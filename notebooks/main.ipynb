{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-26 13:26:34.395503: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-26 13:26:34.959337: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-11-26 13:26:34.959358: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-11-26 13:26:35.036587: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-11-26 13:26:36.195829: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-26 13:26:36.195981: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-26 13:26:36.195989: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import tensorflow as tf\n",
    "from utils.preprocessing import get_gray_images\n",
    "import sys\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_dir = '../data/C-NMC_Leukemia/testing_data/C-NMC_test_final_phase_data'\n",
    "training_dir_base = f'../data/C-NMC_Leukemia/training_data/'\n",
    "fold_0_all_path = 'fold_0/all'\n",
    "fold_0_hem_path = 'fold_0/hem'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-26 13:26:47.032537: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-11-26 13:26:47.033080: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-11-26 13:26:47.033108: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (karl): /proc/driver/nvidia/version does not exist\n",
      "2022-11-26 13:26:47.036541: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "### The code for this lives in notebooks.utils.preprocessing\n",
    "### Get grayscale images as tensors, and labels for both classes\n",
    "img_train_cancer = get_gray_images(training_dir_base+fold_0_all_path)\n",
    "img_train_healthy = get_gray_images(training_dir_base+fold_0_hem_path)\n",
    "train_health_labels = [0 for _ in range(len(img_train_healthy))]\n",
    "train_cancer_labels = [1 for _ in range(len(img_train_cancer))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomForestAccuracy(img_cancer, img_healthy, labels_healthy, labels_cancer, nest=100, mssplit=2, mdepth=None, rstate=100):\n",
    "    ### For random forests, X is our combined image set and y is our combined label set.\n",
    "    X =  np.array(img_cancer + img_healthy)\n",
    "    y = np.array(labels_cancer + labels_healthy)\n",
    "\n",
    "    ### train-test-split our data, and initialize the forest.\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.3, random_state=100)\n",
    "\n",
    "    forest = RandomForestClassifier(n_estimators=nest, random_state=rstate, min_samples_split=mssplit, max_depth=100)\n",
    "\n",
    "    ### The random forests algorithm expects 2 dimensional data at the most.\n",
    "    ### We can accomplish this on our 4-dimensional data by multiplying the last 3 dimensions together to flatten the data\n",
    "    X_shape = X_train.shape\n",
    "    X_tshape = X_test.shape\n",
    "    X_train = X_train.reshape(X_shape[0], X_shape[1] * X_shape[2] * X_shape[3])\n",
    "    X_test = X_test.reshape(X_tshape[0], X_tshape[1] * X_tshape[2] * X_tshape[3])\n",
    "\n",
    "    ### Fit the random forest, try it on the test data, and assess the model's accuracy\n",
    "    forest.fit(X_train,y_train)\n",
    "    predictions = forest.predict(X_test)\n",
    "    return metrics.accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_original = randomForestAccuracy(img_train_cancer, img_train_healthy, train_health_labels, train_cancer_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Random forests, color\n",
    "### We will repeat the steps above, with color images instead.\n",
    "img_train_cancer = get_gray_images(training_dir_base+fold_0_all_path, 128)\n",
    "img_train_healthy = get_gray_images(training_dir_base+fold_0_hem_path, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_128 = randomForestAccuracy(img_train_cancer, img_train_healthy, train_health_labels, train_cancer_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8593012275731823\n",
      "0.8630783758262511\n"
     ]
    }
   ],
   "source": [
    "### I find that there is a negligible (0.4%) difference between full size and 128x128 downscaled images.\n",
    "### Because downscaled images process faster, I will use those\n",
    "print(accuracy_original)\n",
    "print(accuracy_128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Assemble combinations of hyperparameters for tuning.\n",
    "from itertools import product\n",
    "_n_estimators = [10, 50, 100]\n",
    "_min_samples_split = [2, 5, 10]\n",
    "_max_depth = [10, 100, None]\n",
    "_random_state = [50, 100, 256]\n",
    "list_of_lists = [_n_estimators, _min_samples_split, _max_depth, _random_state]\n",
    "all_combinations = list(product(*list_of_lists))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Find the highest accuracy combination of hyperparameters.\n",
    "max_accuracy = -1\n",
    "max_accuracy_params = []\n",
    "for combination in all_combinations:\n",
    "    accuracy = randomForestAccuracy(img_train_cancer, img_train_healthy, train_health_labels, train_cancer_labels, \n",
    "                                    nest=combination[0], mssplit=combination[1], mdepth=combination[2], rstate=combination[3])\n",
    "    \n",
    "    if accuracy > max_accuracy:\n",
    "        max_accuracy = accuracy\n",
    "        max_accuracy_params = combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8649669499527857\n",
      "(100, 10, 10, 100)\n"
     ]
    }
   ],
   "source": [
    "print(max_accuracy)\n",
    "print(max_accuracy_params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "a080823f40af315a9a5d79cf302b32c1e5dfda7957f37ef30447179bcc27d8e4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
