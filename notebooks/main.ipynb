{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import tensorflow as tf\n",
    "from utils.preprocessing import get_gray_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_dir = '../data/C-NMC_Leukemia/testing_data/C-NMC_test_final_phase_data'\n",
    "training_dir_base = f'../data/C-NMC_Leukemia/training_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### The code for this lives in notebooks.utils.preprocessing\n",
    "### Loading the images and grey scaling them\n",
    "lukemia_images = get_gray_images(training_dir_base+'fold_0/all')\n",
    "normal_images = get_gray_images(training_dir_base+'fold_0/hem')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "### This wll add a reference to the image as the key and the label for that image in the value\n",
    "### Using this makes the assumption that no two images are identical \n",
    "\n",
    "image_dict = {}\n",
    "for l_image in lukemia_images:\n",
    "    image_dict[l_image.ref()] = True\n",
    "for n_image in normal_images:\n",
    "    image_dict[n_image.ref()] = False\n",
    "\n",
    "### This will throw and error if there are duplicate images in the data \n",
    "assert len(image_dict) == len(lukemia_images) + len(normal_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "### This is to get the tensor of the image and the label for the image in order since we had to create the labels\n",
    "image_list = []\n",
    "image_lab = []\n",
    "for key, value in image_dict.items():\n",
    "    image_list.append(key.deref())\n",
    "    image_lab.append(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Coerse these into np.arrays and the reshape for traning\n",
    "image_list = np.array(image_list).reshape(len(image_list), 450, 450)\n",
    "image_lab = np.array(image_lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "### First model creation\n",
    "### Note: this is likely going to need tuning\n",
    "model = tf.keras.Sequential(tf.keras.layers.Flatten(input_shape = [450, 450]))\n",
    "model.add(tf.keras.layers.Dense(500, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(units=1, activation='relu'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "111/111 [==============================] - 15s 136ms/step - loss: 10.4830 - accuracy: 0.3204\n",
      "Epoch 2/10\n",
      " 52/111 [=============>................] - ETA: 8s - loss: 10.2895 - accuracy: 0.3329"
     ]
    }
   ],
   "source": [
    "### Train the model\n",
    "history = model.fit(image_list, image_lab, epochs=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a080823f40af315a9a5d79cf302b32c1e5dfda7957f37ef30447179bcc27d8e4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
